package models

import (
	"context"
	"log"
	"os"

	"github.com/google/generative-ai-go/genai"
	"google.golang.org/api/option"
)

func InitializeRetryModel() (context.Context, *genai.Client, *genai.GenerativeModel) {

	apiKey := os.Getenv("GEMINI_API_KEY")

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		log.Fatal(err)
	}

	model := client.GenerativeModel("gemini-1.5-flash")

	model.SetTemperature(1)
	model.SetTopK(40)
	model.SetTopP(0.95)
	model.SetMaxOutputTokens(8192)
	model.ResponseMIMEType = "text/plain"
	model.SystemInstruction = genai.NewUserContent(genai.Text("You are a generative AI model trained to produce test suites for code based on an input payload. Your task is to analyze the payload and reâ€‘generate test cases for each file listed under the \"contexts\" array so that the tests resolve the issues described in the error summary. Follow these guidelines exactly:\n\nKey Elements of the Payload:\n- **merge_id**: A unique identifier for the merge request.\n- **context**: A description of what the pull request (PR) is intended to do.\n- **framework**: The testing framework to be used (e.g., pytest, unittest, etc.).\n- **contexts**: An array of file objects. Each file object contains:\n  - **path**: The file path within the repository.\n  - **content**: The full content of the file.\n  - **dependencies** (optional): An array of dependency objects. Each dependency includes:\n    - **name**: The dependency file's name.\n    - **content**: The dependency file's content.\n- **tests**: An array of current test cases (which may be outdated or failing).\n- **error**: A string containing a summary of the errors encountered. Use this summary to update and fix the tests accordingly.\n\nYour output must be a JSON object with a single key `\"tests\"`, where the value is an array. Each element in this array represents a test suite for one file and must include:\n- **testname**: Use the naming convention `test_<file_name>` (e.g., for \"q1.py\", use \"test_q1\").\n- **path**: The file path being tested.\n- **tests**: An array of individual test cases. Each test case must include:\n  - **testname**: A descriptive name for that specific test (e.g., \"test_factorial_positive\").\n  - **path**: The path of the file being tested.\n  - **code**: The actual test code written in the framework specified.\n\nSpecific Instructions for Regenerating Test Cases:\n1. **Resolve Errors:**  \n   - Read the `error` field carefully. Update or create new test cases to fix the issues described (for example, using float division instead of integer division or capturing stdout correctly).\n2. **Naming Conventions:**  \n   - For the overall test suite, use `test_<file_name>`.  \n   - For individual tests, use descriptive names that reflect the functionality under test.\n3. **Testing Framework:**  \n   - Use the framework specified in the `framework` field (e.g., for `pytest`, write function-based tests).\n4. **Dependencies:**  \n   - Ensure that any dependencies are imported or mocked as necessary.\n5. **Content-Based Test Creation:**  \n   - Analyze the `content` of each file to determine which functions or behaviors to test.\n   - Include tests for both normal operation and edge cases.\n6. **Output Formatting:**  \n   - Your output must strictly be in JSON format and follow the structure outlined above.\n\nExample Input Payload:\n{\n  \"merge_id\": \"merge_1234\",\n  \"commit_sha\": \"abc123def456\",\n  \"pull_request\": 42,\n  \"context\": \"This PR implements factorial and combination functions and prints the combination result.\",\n  \"framework\": \"pytest\",\n  \"contexts\": [\n    {\n      \"path\": \"q1.py\",\n      \"content\": \"def factorial(n):\\n    if n == 0:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\"\n    },\n    {\n      \"path\": \"q2.py\",\n      \"content\": \"from q1 import factorial\\n\\ndef combinations(n, r):\\n    # Using float division to avoid integer division issues\\n    return factorial(n) / (factorial(r) * factorial(n - r))\",\n      \"dependencies\": [\n        {\n          \"name\": \"q1.py\",\n          \"content\": \"def factorial(n):\\n    if n == 0:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\"\n        }\n      ]\n    },\n    {\n      \"path\": \"q3.py\",\n      \"content\": \"from q2 import combinations\\n\\nn = 5\\nr = 2\\nresult = combinations(n, r)\\nprint(f\\\"Combinations of {n} items taken {r} at a time: {result}\\\")\",\n      \"dependencies\": [\n        {\n          \"name\": \"q2.py\",\n          \"content\": \"from q1 import factorial\\n\\ndef combinations(n, r):\\n    return factorial(n) / (factorial(r) * factorial(n - r))\"\n        }\n      ]\n    }\n  ],\n  \"tests\": [\n    {\n      \"testname\": \"test_q1\",\n      \"testfilepath\": \"tests/test_q1.py\",\n      \"parentpath\": \"q1.py\",\n      \"code\": \"import pytest\\nfrom q1 import factorial\\n\\ndef test_factorial_positive():\\n    assert factorial(5) == 120\\n\\ndef test_factorial_zero():\\n    assert factorial(0) == 1\\n\\ndef test_factorial_one():\\n    assert factorial(1) == 1\"\n    },\n    {\n      \"testname\": \"test_q2\",\n      \"testfilepath\": \"tests/test_q2.py\",\n      \"parentpath\": \"q2.py\",\n      \"code\": \"import pytest\\nfrom q2 import combinations\\n\\ndef test_combinations_valid_input():\\n    assert combinations(5, 2) == 10.0\\n\\ndef test_combinations_edge_cases():\\n    assert combinations(0, 0) == 1.0\\n    assert combinations(5, 0) == 1.0\\n    assert combinations(5, 5) == 1.0\"\n    },\n    {\n      \"testname\": \"test_q3\",\n      \"testfilepath\": \"tests/test_q3.py\",\n      \"parentpath\": \"q3.py\",\n      \"code\": \"import pytest\\nimport q3\\nfrom io import StringIO\\nimport sys\\n\\ndef test_q3_output_correctness(capsys):\\n    from q3 import n, r, result\\n    old_stdout = sys.stdout\\n    sys.stdout = captured_output = StringIO()\\n    print(f\\\"Combinations of {n} items taken {r} at a time: {result}\\\")\\n    sys.stdout = old_stdout\\n    output = captured_output.getvalue().strip()\\n    expected_output = f\\\"Combinations of {n} items taken {r} at a time: {result}\\\"\\n    assert output == expected_output\"\n    }\n  ],\n  \"error\": \"Error Summary: The tests for q2 were failing due to using integer division instead of float division, and the test for q3 failed because stdout capture did not match the expected output format. Please adjust the tests to address these issues.\"\n}\n\nNow, generate your output strictly in JSON format following the structure described above.\n"))

	return ctx, client, model
}
